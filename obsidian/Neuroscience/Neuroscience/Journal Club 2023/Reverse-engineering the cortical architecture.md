---
Authors:
  - Rebecca L. Jackson
  - Timothy T. Rogers
  - Matthew A. Lambon Ralph
_links:
  - https://www.nature.com/articles/s41562-020-01034-z
---
# Main Ideas
This papers discuss a reverse engineering approach to find [[neurocomputational building block]] that support [[controlled semantic cognition]] by systematically varying the structure of computational model and assess the **functional consequences**.

This paper claims to found the best architectural properties that best promote two core functions of [[semantic system]].

> [!Core functions]
> - Abstraction
> Brain must have an ability to abstract the *context sensitive* information into *context invariant* concept that is useful to anticipate the future event.
> - Realization
> Moreover, brain must also have a capacity to bind some context invariant information to specific context of immediate task at hand.

## Goals
- Best neurocomputational machinery suitable for two core functions of **semantic cognition**
## Method
- Varying the computational building blocks of *spokes and hubs* model and evaluate the functional capacity
## Claims
The authors claims that above two functions are best achieved in models with a single, deep **multimodal hub** with **sparse connections** from **modality-specific regions**.

## Required Knowledges
### Reverse engineering
### Multimodal hub
### Sparse connection
### Modality specific region
### Quantification of functional performance
#### Abstraction
#### Realization

# Contents
## Core functions for semantic cognition
Research in semantic cognition largely focused on how *input* information (such as that from sensory, motor and linguistic) be represented with [[conceptual structure]]. This ability is thought to be arise from sensitivity to patterns of *covariation* in experience. That is conceptually information from one **semantic concept**.

> [!Covariation]
> Is this essentially relevant to **vector  encoding** of information?

For example, when we are talking about *birds*. They possess many common features such as beaks, feather, wings, flying ability and even the name *bird*. But birds do vary **wildly** in appearances.

So, in this view, **[concepts](semantic%20concept)** reflect [clusters](cluster) in the **high-order** covariance structure of experience.

> [!Against the flow]
> Is there such the case where concept should be in the low-order covariance structure?

However, such the idea is not suit to learning experience distributed across many [episodes](episode). Birds do not fly while lay eggs, but they, somehow, are bundled together as one whole concept. Each episodes provides a partial information about concepts while such a exposure may be highly context and modality specific. The example here is learning about bird physiology without dissecting it. So the [[abstraction]] here **must** extract covarying information from these contexts.

Moreover, when we talk about the second core functional requirements for semantic systems, it seems to be at odd with the first core function.

